{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import *\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.getcwd() + '/log-data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.getcwd() + '/log-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.getcwd() + '/song-data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.getcwd() + '/song-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data_path = os.getcwd() + '/song-data/song_data/*/*/*/*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(song_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|  artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|                 |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "|AREBBGV1187FB523D2|           null|      Houston, TX|            null|Mike Jones (Featu...|173.66159|        1|SOOLYAZ12A6701F4A6|Laws Patrolling (...|   0|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|Morris Plains, NJ|       -74.47995|The Dillinger Esc...|207.77751|        1|SOBBUGU12A8C13E95D|Setting Fire to S...|2004|\n",
      "|ARPBNLO1187FB3D52F|       40.71455|     New York, NY|       -74.00712|            Tiny Tim| 43.36281|        1|SOAOIBZ12AB01815BE|I Hold Your Hand ...|2000|\n",
      "|ARDNS031187B9924F0|       32.67828|          Georgia|       -83.22295|          Tim Wilson|186.48771|        1|SONYPOM12A8C13B2D7|I Think My Wife I...|2005|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_path = os.getcwd() + '/log-data/*.json'\n",
    "df_log = spark.read.json(log_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = df.select('song_id', 'title', 'artist_id', 'year', 'duration')\\\n",
    "    .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_df = df.select('artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude')\\\n",
    "    .dropDuplicates()\\\n",
    "    .withColumnRenamed('artist_name', 'name')\\\n",
    "    .withColumnRenamed('artist_location', 'location')\\\n",
    "    .withColumnRenamed('artist_latitude', 'latitude')\\\n",
    "    .withColumnRenamed('artist_longitude', 'longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+----+----+-------+\n",
      "|         start_time|hour|day|week|year|weekday|\n",
      "+-------------------+----+---+----+----+-------+\n",
      "|2018-11-15 00:30:26|   0| 15|  46|2018|      5|\n",
      "|2018-11-15 00:41:21|   0| 15|  46|2018|      5|\n",
      "|2018-11-15 00:45:41|   0| 15|  46|2018|      5|\n",
      "|2018-11-15 01:57:51|   1| 15|  46|2018|      5|\n",
      "|2018-11-15 03:29:37|   3| 15|  46|2018|      5|\n",
      "+-------------------+----+---+----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigint_from_ms = udf(lambda x: str(int(x/1000)))\n",
    "\n",
    "df_log = df_log.withColumn('ts_ms', bigint_from_ms(df_log.ts))\n",
    "\n",
    "df_log = df_log.withColumn('timestamp', from_unixtime(df_log.ts_ms))\n",
    "\n",
    "time_df = df_log.withColumn('hour', hour(df_log.timestamp))\\\n",
    "    .withColumn('day', dayofmonth(df_log.timestamp))\\\n",
    "    .withColumn('week', weekofyear(df_log.timestamp))\\\n",
    "    .withColumn('month', month(df_log.timestamp))\\\n",
    "    .withColumn('year', year(df_log.timestamp))\\\n",
    "    .withColumn('weekday', dayofweek(df_log.timestamp))\\\n",
    "    .withColumnRenamed('timestamp', 'start_time')\\\n",
    "    .select('start_time', 'hour', 'day', 'week', 'year', 'weekday')\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+-------+-----+-------+---------+----------+--------------------+--------------------+\n",
      "|songplay_id|         start_time|user_id|level|song_id|artist_id|session_id|            location|          user_agent|\n",
      "+-----------+-------------------+-------+-----+-------+---------+----------+--------------------+--------------------+\n",
      "|          0|2018-11-15 00:30:26|     26| free|   null|     null|       583|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|\n",
      "|          1|2018-11-15 00:41:21|     26| free|   null|     null|       583|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|\n",
      "|          2|2018-11-15 00:45:41|     26| free|   null|     null|       583|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|\n",
      "|          3|2018-11-15 03:44:09|     61| free|   null|     null|       597|Houston-The Woodl...|\"Mozilla/5.0 (Mac...|\n",
      "+-----------+-------------------+-------+-----+-------+---------+----------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplay_df = df_log.filter(df_log.page == 'NextSong')\\\n",
    "    .join(df, (df_log.song == df.title) & (df_log.artist == df.artist_name), how='left')\\\n",
    "    .withColumn(\"songplay_id\", monotonically_increasing_id())\\\n",
    "    .select('songplay_id', 'timestamp', 'userId', 'level', 'song_id', 'artist_id', 'sessionId', 'location', 'userAgent')\\\n",
    "    .withColumnRenamed('timestamp', 'start_time')\\\n",
    "    .withColumnRenamed('userId', 'user_id')\\\n",
    "    .withColumnRenamed('sessionId', 'session_id')\\\n",
    "    .withColumnRenamed('userAgent', 'user_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     84|   Shakira|     Hunt|     F| free|\n",
      "|     65|     Amiya| Davidson|     F| paid|\n",
      "|     59|      Lily|   Cooper|     F| free|\n",
      "|     40|    Tucker| Garrison|     M| free|\n",
      "|     76|    Jayden|    Duffy|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_ts_user_df = df_log.groupBy('userId') \\\n",
    "    .max('ts')\\\n",
    "    .withColumnRenamed('max(ts)', 'max_ts')\\\n",
    "    .withColumnRenamed('userId', 'user_id')\n",
    "\n",
    "mask = (df_log.userId == max_ts_user_df.user_id) & (df_log.ts == max_ts_user_df.max_ts)\n",
    "\n",
    "user_df = df_log.join(max_ts_user_df, mask, how='inner')\\\n",
    "    .select('userId', 'firstName', 'lastName', 'gender', 'level')\\\n",
    "    .withColumnRenamed('userId', 'user_id')\\\n",
    "    .withColumnRenamed('firstName', 'first_name')\\\n",
    "    .withColumnRenamed('lastName', 'last_name')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
